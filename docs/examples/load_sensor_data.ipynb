{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSingle Dataset\n==============\n\nA simple example on how to work with a single Dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom pathlib import Path\n\nfrom NilsPodLib import Dataset\n\nFILEPATH = Path('../tests/test_data/synced_sample_session/NilsPodX-7FAD_20190430_0933.bin')\n\n# Create a Dataset Object from the bin file\ndataset = Dataset.from_bin_file(FILEPATH)\n\n# You can access the metainformation about your dataset using the `info` attr.\n# For a full list of available attributes see NilsPodLib.header.HeaderFields\nprint('Sensor ID:', dataset.info.sensor_id)\nprint('Start Date (UTC):', dataset.info.utc_datetime_start)\nprint('Stop Date (UTC):', dataset.info.utc_datetime_stop)\nprint('Enabled Sensors:', dataset.info.enabled_sensors)\n\n# You can access the individual sensor data directly from the dataset object using the names provided\n# in dataset.info.enabled_sensors\ndatastream_acc = dataset.acc\n\n# If a sensor is disabled, this will return `None`\nprint('Analog is disabled:', dataset.analog is None)\n\n# Access the data of a datastream object as a numpy.array using the `data` attribute\nprint('The acc recordings are {}D and have the length {}'.format(*datastream_acc.data.T.shape))\n\n# Convenience methods are available for common operations. E.g. Norm or downsample\nplt.figure()\nplt.title('Acc Norm')\nplt.plot(datastream_acc.norm())\nplt.show()\n\ndownsampled_datastream = datastream_acc.downsample(factor=2)\nprint('The new datastream has a length of', len(downsampled_datastream.data))\n\n# However, for many operations it makes more sense to apply them to the Dataset instead of the Datastream.\n# This will apply the operations to all Datastream and return a new Dataset object\n\ndownsampled_dataset = dataset.downsample(factor=2)\nprint('Acc has now a length of', len(downsampled_dataset.acc.data))\nprint('Gyro has now a length of', len(downsampled_dataset.gyro.data))\n\n# By default this returns a copy of the dataset and all datastreams. If this is a performance concern, the dataset can\n# be modified inplace:\n\ndownsampled_dataset = dataset.downsample(factor=2, inplace=True)\nprint('The old and the new are identical:', id(dataset) == id(downsampled_dataset))\n\n# Usually, before using any data it needs to be calibrated. The dataset object offers factory_calibrations for all\n# important sensors. These convert the datastreams into physical units\n\ndataset_cal = dataset.factory_calibrate_baro()\n# For acc and gyro a convenience method is provided.\ndataset_cal = dataset_cal.factory_calibrate_imu()\n\n# However, for more precise measurements an actual IMU Calibration using the `calibrate_{acc,gyro,imu}` methods should\n# be performed.\n\n# After calibration and initial operations on all datastreams, the easiest way to interface with further processing\n# pipelines is a conversion into a pandas DataFrame\n\ndf = dataset_cal.data_as_df()\n\nprint(df.head())\n\ndf.plot()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}