{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nSessions\n=========\n\nA simple example showing how to work with Sensor Sessions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport numpy as np\n\nfrom NilsPodLib import Dataset, Session, SyncedSession\n\nFILEPATH = Path('../tests/test_data/synced_sample_session/')\n\n# A session consists of multiple datasets. By default this is also the way to create one\ndatasets = [Dataset.from_bin_file(d) for d in FILEPATH.glob('*.bin')]\nsession = Session(datasets)\nprint('This session has {} datasets'.format(len(session.datasets)))\n\n# However, in many cases it is easier to use one of the Session constructors:\nsession = Session.from_folder_path(FILEPATH, filter_pattern='*.bin')\nprint('This session has {} datasets'.format(len(session.datasets)))\n\n# Like Datasets contain convenience methods to act on all Datastreams, Sessions provide methods that work on all\n# datasets\n\ndownsampled_session = session.downsample(factor=2)\nfor ds in downsampled_session.datasets:\n    for name, d in ds.datastreams:\n        print('{} of {} has the length {}'.format(name, ds.info.sensor_id, len(d.data)))\n\n# Further you can use the Proxy Attribute `info` to access the header infos of all sensors at the same time\nprint('The included sensors are:', session.info.sensor_id)\nprint('The samplingrates are:', session.info.sampling_rate_hz)\nprint('The enabled sensor are:', session.info.enabled_sensors)\n\n# The library differentiates between synchronised and not synchronised session.\n# If your session is synchronised your should use a SyncedSession\n\nsession = SyncedSession.from_folder_path(FILEPATH)\n\n# This will also validate that all datasets are compatible to be syncronised.\n# If you need to switch off this validation, you can disable it using:\nSyncedSession.VALIDATE_ON_INIT = False\nsession = SyncedSession.from_folder_path(FILEPATH)\n\n# For synced sessions you can get the datasets of the master and the slaves separately\n\nprint('The master of the session is', session.master.info.sensor_id)\nprint('The slaves of the session are', [d.info.sensor_id for d in session.slaves])\n\n# To make use of the sync information, all datasets need to be aligned. This can be done using the `cut_to_syncregion`\n# method.\n\ncut_session = session.cut_to_syncregion()\n\n# After this all session are aligned and the dataset counter are identical\n\nfor d in cut_session.slaves:\n    if np.array_equal(d.counter, cut_session.master.counter) is True:\n        print('{} has the same counter than master ({})'.format(d.info.sensor_id, cut_session.master.info.sensor_id))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}